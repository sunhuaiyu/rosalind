# rosalind_ba10k
'''
Baum-Welch Learning Problem

Given: A sequence of emitted symbols x = x1 . . . xn in an alphabet A, generated by 
a k-state HMM with unknown transition and emission probabilities, 
initial Transition and Emission matrices and a number of iterations I.

Return: A matrix of transition probabilities Transition and a matrix of emission 
probabilities Emission that maximizes Pr(x,π) over all possible transition and 
emission matrices and over all hidden paths π.
'''
import numpy as np
from numpy import log, exp
from pandas import DataFrame
from io import StringIO

def forward_backward(Y, states, A, B, init_state_p):
    '''Given: A observation sequence Y (1...t...T), the states set X (1...i...N),  
    and transition matrix A and emission matrix B of an HMM.
    Return: The probability Pr(πi = k|Y) that the HMM was in state k at step t 
    (for each state k and each step i).'''

    n = len(Y)          # n-length observations
    m = len(states)     # m states
    
    # initialize forward and backward score table
    V_f = np.zeros(shape=(m, n), dtype=np.float64)
    V_b = V_f.copy()

    # forward
    V_f[:, 0] = init_state_p * B[:, Y[0]]
    for t in range(n-1):
        V_f[:, t+1] = B[:, Y[t+1]] * (V_f[:, t].dot(A)) 
            
    # backward
    V_b[:, -1] = 1.0
    for t in range(n-2, -1, -1):
        V_b[:, t] = A.dot(V_b[:, t+1] * B[:, Y[t+1]])
        
    return V_f, V_b

def Baum_Welch(Y, states_num, A, B, n_iter):

    m = len(states_num)
    init_state_p = 1.0 / m  # assuming equal initial probabilities of all states
    ksi = np.zeros((len(Y)-1, m, m), dtype=np.float64)

    for i in range(n_iter):
        alpha, beta = forward_backward(Y, states_num, A, B, init_state_p)
        g = alpha * beta / (alpha * beta).sum(0, keepdims=True)

        for t in range(len(Y)-1):
            S = alpha[:, t].dot(A).dot(beta[:, t+1] * B[:, Y[t+1]])
            ksi[t] = A * np.outer(alpha[:, t], beta[:, t+1] * B[:, Y[t+1]]) / S
                               
        #init_state_p = g[:, 0]   
        A = ksi.sum(0) / g[:, :-1].sum(1, keepdims=True)
        for v in alphabet_num:
            B[:, v] =  g[:, Y==v].sum(1) / g.sum(1)
    
    return A, B


f = open('rosalind_ba10k.txt').read().rstrip().split('\n--------\n')
n_iter = int(f[0].rstrip())
alphabet = f[2].split()
alphabet_num = list(range(len(alphabet)))
Y = np.array([dict(zip(alphabet, alphabet_num))[i] for i in f[1]])  #observation sequence
states = f[3].split()
m = len(states)
states_num = list(range(m))

A = np.array([line.split()[1:] for line in f[4].split('\n')[1:]], dtype=np.float64)
B = np.array([line.split()[1:] for line in f[5].split('\n')[1:]], dtype=np.float64)

A, B = Baum_Welch(Y, states_num, A, B, n_iter)

f = StringIO()
DataFrame(A.round(3), index=states, columns=states).to_csv(f, sep='\t', float_format='%g')
f.write('--------\n')
DataFrame(B.round(3), index=states, columns=alphabet).to_csv(f, sep='\t',float_format='%g')

open('rosalind_ba10k_sub.txt', 'wt').write(f.getvalue().rstrip())
f.close()
